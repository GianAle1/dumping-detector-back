{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac24977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando el producto: 'electronic component kit' en 2 p√°ginas de Alibaba...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 10:37:43,140 - INFO - WebDriver inicializado correctamente.\n",
      "2025-12-09 10:37:43,145 - INFO - Cargando Alibaba: P√°gina 1 -> https://www.alibaba.com/trade/search?SearchText=electronic+component+kit&page=1\n",
      "2025-12-09 10:38:24,491 - WARNING - Reintento Alibaba p1 (1): Message: \n",
      "\n",
      "2025-12-09 10:38:57,508 - WARNING - Reintento Alibaba p1 (2): Message: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Set\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importaciones de Selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException,\n",
    "    NoSuchElementException,\n",
    "    StaleElementReferenceException,\n",
    "    WebDriverException,\n",
    ")\n",
    "\n",
    "# Para an√°lisis y visualizaci√≥n en Notebook\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Configuraci√≥n de Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- 1. BASE SCRAPER (Driver Handling) ---\n",
    "\n",
    "class BaseScraper:\n",
    "    \"\"\"Clase base para manejar la inicializaci√≥n y cierre del WebDriver.\"\"\"\n",
    "    \n",
    "    def __init__(self, headless: bool = True, driver_path: Optional[str] = None):\n",
    "        \"\"\"Inicializa el WebDriver de Chrome.\"\"\"\n",
    "        self.driver: Optional[webdriver.Chrome] = None\n",
    "        self.headless = headless\n",
    "        self.driver_path = driver_path # Ruta opcional si el driver no est√° en el PATH\n",
    "        self._initialize_driver()\n",
    "\n",
    "    def _initialize_driver(self):\n",
    "        \"\"\"Configura y lanza el WebDriver.\"\"\"\n",
    "        chrome_options = Options()\n",
    "        # Opciones recomendadas para evitar detecciones de bot\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "        chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "        \n",
    "        if self.headless:\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "            \n",
    "        try:\n",
    "            if self.driver_path:\n",
    "                service = ChromeService(executable_path=self.driver_path)\n",
    "                self.driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "            else:\n",
    "                # Asume que el driver est√° en el PATH (o en el mismo directorio si usas Colab/Jupyter con un driver descargado)\n",
    "                self.driver = webdriver.Chrome(options=chrome_options)\n",
    "            logging.info(\"WebDriver inicializado correctamente.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al inicializar WebDriver: {e}. Aseg√∫rate de que ChromeDriver est√° instalado y en el PATH.\")\n",
    "            raise\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Cierra el WebDriver.\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            self.driver = None\n",
    "            logging.info(\"WebDriver cerrado.\")\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.close()\n",
    "\n",
    "# --- 2. UTILIDADES COMPARTIDAS ---\n",
    "\n",
    "BLOCK_PATTERNS = (\n",
    "    \"punish\", \"unusual traffic\", \"error:gvs\", \"robot check\",\n",
    "    \"are you a robot\", \"are you human\", \"please verify you are a human\",\n",
    "    \"verify you are human\", \"security verification\", \"complete the captcha\",\n",
    "    \"captcha verification\", \"please complete the captcha\",\n",
    ")\n",
    "_RANGE_SPLIT_PATTERN = re.compile(r\"(?<=\\d)\\s*[-‚Äì‚Äî]\\s*(?=\\d)\")\n",
    "_currency_re = re.compile(r\"(US\\$|S/|[$‚Ç¨¬£¬•])\")\n",
    "_rating_re = re.compile(r\"([\\d.]+)\\s*/\\s*5(?:\\.0)?\\s*\\((\\d+)\\)\")\n",
    "_years_re = re.compile(r\"(\\d+)\\s*(?:a√±os|years?)\", re.I)\n",
    "_percent_re = re.compile(r\"(\\d+)\\s*%\")\n",
    "\n",
    "def limpiar_precio(texto: Optional[str]) -> Optional[float]:\n",
    "    \"\"\"Limpia y convierte texto de precio a float.\"\"\"\n",
    "    def _normalizar(texto_unitario: str) -> Optional[float]:\n",
    "        cleaned = re.sub(r\"[^0-9.,]\", \"\", texto_unitario)\n",
    "        if not cleaned: return None\n",
    "        # L√≥gica de detecci√≥n de separador decimal (copiada de tu c√≥digo original)\n",
    "        decimal_sep: Optional[str] = None\n",
    "        has_dot = \".\" in cleaned\n",
    "        has_comma = \",\" in cleaned\n",
    "        if has_dot and has_comma:\n",
    "            decimal_sep = \",\" if cleaned.rfind(\",\") > cleaned.rfind(\".\") else \".\"\n",
    "        elif has_dot:\n",
    "            if len(cleaned.rpartition(\".\")[-1]) in (1, 2): decimal_sep = \".\"\n",
    "        elif has_comma:\n",
    "            if len(cleaned.rpartition(\",\")[-1]) in (1, 2): decimal_sep = \",\"\n",
    "\n",
    "        if decimal_sep:\n",
    "            int_part, dec_part = cleaned.rsplit(decimal_sep, 1)\n",
    "            int_digits = re.sub(r\"[^0-9]\", \"\", int_part)\n",
    "            dec_digits = re.sub(r\"[^0-9]\", \"\", dec_part)\n",
    "            number_str = f\"{int_digits}.{dec_digits or '0'}\"\n",
    "        else:\n",
    "            number_str = re.sub(r\"[^0-9]\", \"\", cleaned)\n",
    "            if not number_str: return None\n",
    "            \n",
    "        try:\n",
    "            return float(number_str)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    if not texto: return None\n",
    "    texto = texto.strip()\n",
    "    # Si es un rango de precios, toma el m√≠nimo (el primero)\n",
    "    if _RANGE_SPLIT_PATTERN.search(texto):\n",
    "        partes = [p.strip() for p in _RANGE_SPLIT_PATTERN.split(texto) if p.strip()]\n",
    "        if partes: texto = partes[0]\n",
    "    \n",
    "    return _normalizar(texto)\n",
    "\n",
    "def limpiar_cantidad(texto: Optional[str]) -> int:\n",
    "    \"\"\"Limpia y convierte texto de cantidad (ej. MOQ, ventas) a int.\"\"\"\n",
    "    if texto is None: return 0\n",
    "    t = texto.strip().lower().replace(\"+\", \"\")\n",
    "    if not t: return 0\n",
    "    mult = 1\n",
    "    if re.search(r\"k\\b\", t):\n",
    "        mult = 1000\n",
    "        t = re.sub(r\"k\\b\", \"\", t)\n",
    "    n = limpiar_precio(t) or 0.0\n",
    "    return int(round(n * mult))\n",
    "\n",
    "def detectar_moneda(texto: str) -> Optional[str]:\n",
    "    \"\"\"Detecta el s√≠mbolo de la moneda.\"\"\"\n",
    "    if not texto: return None\n",
    "    m = _currency_re.search(texto)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def parse_rating(texto: str) -> (Optional[float], Optional[int]):\n",
    "    \"\"\"Parsea el score y el conteo de ratings.\"\"\"\n",
    "    if not texto: return (None, None)\n",
    "    m = _rating_re.search(texto)\n",
    "    if not m: return (None, None)\n",
    "    try:\n",
    "        return float(m.group(1)), int(m.group(2))\n",
    "    except:\n",
    "        return (None, None)\n",
    "\n",
    "def parse_moq(texto: str) -> (Optional[int], Optional[str]):\n",
    "    \"\"\"Parsea el valor num√©rico del MOQ (Min Order Quantity).\"\"\"\n",
    "    if not texto: return (None, None)\n",
    "    m = re.search(r\"(\\d[\\d.,]*)\", texto)\n",
    "    if not m: return (None, texto.strip())\n",
    "    try:\n",
    "        val = limpiar_cantidad(m.group(1))\n",
    "    except:\n",
    "        val = None\n",
    "    return val, texto.strip()\n",
    "\n",
    "def parse_repeat_rate(texto: str) -> Optional[int]:\n",
    "    \"\"\"Parsea la tasa de repetici√≥n de compra (porcentaje).\"\"\"\n",
    "    if not texto: return None\n",
    "    m = _percent_re.search(texto)\n",
    "    if not m: return None\n",
    "    try:\n",
    "        return int(m.group(1))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# --- 3. ALIBABA SCRAPER ---\n",
    "\n",
    "class AlibabaScraper(BaseScraper):\n",
    "    \"\"\"Scraper Alibaba (layout searchx/fy26) con scroll humano y datos extra.\"\"\"\n",
    "\n",
    "    # Contenedores de cards (selectores m√∫ltiples para robustez)\n",
    "    CARD_CONTAINERS: List[str] = [\n",
    "        \"div.fy26-product-card-content\",\n",
    "        \"div.searchx-product-card\",\n",
    "        \"div.card-info.gallery-card-layout-info\",\n",
    "    ]\n",
    "\n",
    "    # Selectores internos (selectores m√∫ltiples para robustez)\n",
    "    A_CARD: List[str] = [\"h2.searchx-product-e-title a\", \"a.searchx-product-link-wrapper\", \"a\"]\n",
    "    TITLE: List[str] = [\"h2.searchx-product-e-title span\", \"h2.searchx-product-e-title a\", \"h2.search-card-e-title a\", \"h1, h2, h3\"]\n",
    "    PRICE: List[str] = [\"div.searchx-product-price-price-main\", \"div.searchx-product-price\", \"div.search-card-e-price-main\"]\n",
    "    PRICE_ORIGINAL: List[str] = [\"del\", \"s\", \".price-origin\"]\n",
    "    DISCOUNT: List[str] = [\".discount\", \".sale-tag\", \"[data-discount]\"]\n",
    "    SUPPLIER_NAME: List[str] = [\"a.searchx-product-e-company\", \"a.search-card-e-company\"]\n",
    "    SUPPLIER_YEAR_COUNTRY: List[str] = [\"a.searchx-product-e-supplier__year\"]\n",
    "    VERIFIED_BADGE: List[str] = [\".verified-supplier-icon__wrapper\", \"img.searchx-verified-icon\"]\n",
    "    RATING: List[str] = [\"span.searchx-product-e-review\"]\n",
    "    SELLING_POINTS: List[str] = [\".searchx-selling-point-text\"]\n",
    "\n",
    "    # ----------------- utilidades privadas -----------------\n",
    "\n",
    "    def _accept_banners(self, timeout: int = 5):\n",
    "        \"\"\"Intenta aceptar cookies/banners para evitar interrupci√≥n.\"\"\"\n",
    "        candidates = [\n",
    "            (By.XPATH, \"//button[contains(., 'Aceptar') or contains(., 'Accept')]\"),\n",
    "            (By.XPATH, \"//button[contains(., 'Allow all')]\"),\n",
    "            (By.CSS_SELECTOR, \"[role='button'][aria-label*='accept' i]\"),\n",
    "        ]\n",
    "        for by, sel in candidates:\n",
    "            try:\n",
    "                btn = WebDriverWait(self.driver, timeout).until(EC.element_to_be_clickable((by, sel)))\n",
    "                btn.click()\n",
    "                time.sleep(0.3)\n",
    "                logging.info(\"Banner de cookies aceptado.\")\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    def _human_scroll_until_growth(self, max_scrolls: int = 16, pause: float = 1.0):\n",
    "        \"\"\"Simula scroll de humano para cargar contenido din√°mico.\"\"\"\n",
    "        last_height = self.driver.execute_script(\"return document.body.scrollHeight\") if self.driver else 0\n",
    "        for i in range(max_scrolls):\n",
    "            if not self.driver: break\n",
    "            \n",
    "            # Intenta scroll normal\n",
    "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(pause)\n",
    "            \n",
    "            new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            # Si la altura no creci√≥, realiza un scroll extra para forzar la carga\n",
    "            if new_height <= last_height:\n",
    "                self.driver.execute_script(\"window.scrollBy(0, 700);\")\n",
    "                time.sleep(pause)\n",
    "                new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height <= last_height:\n",
    "                     # Si sigue sin crecer, asumimos que hemos llegado al final o est√° bloqueado\n",
    "                    break\n",
    "            \n",
    "            last_height = new_height\n",
    "\n",
    "    def _first_match(self, root, selectors: List[str]):\n",
    "        \"\"\"Busca el primer elemento que coincida con la lista de selectores CSS.\"\"\"\n",
    "        if not self.driver: return None\n",
    "        for css in selectors:\n",
    "            try:\n",
    "                el = root.find_element(By.CSS_SELECTOR, css)\n",
    "                if el:\n",
    "                    return el\n",
    "            except Exception:\n",
    "                continue\n",
    "        return None\n",
    "\n",
    "    def _find_all_any(self, selectors: List[str], timeout: int = 10) -> List:\n",
    "        \"\"\"Espera a que cualquier selector est√© presente y retorna todos los elementos.\"\"\"\n",
    "        if not self.driver: return []\n",
    "        for css in selectors:\n",
    "            try:\n",
    "                WebDriverWait(self.driver, timeout).until(\n",
    "                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, css))\n",
    "                )\n",
    "                els = self.driver.find_elements(By.CSS_SELECTOR, css)\n",
    "                if els:\n",
    "                    return els\n",
    "            except TimeoutException:\n",
    "                continue\n",
    "        return []\n",
    "\n",
    "    @staticmethod\n",
    "    def _resolve_text(node) -> Optional[str]:\n",
    "        \"\"\"Obtiene el texto de un elemento Selenium o BeautifulSoup.\"\"\"\n",
    "        if node is None: return None\n",
    "        # Intenta con Selenium (get_attribute para innerText)\n",
    "        get_attribute = getattr(node, \"get_attribute\", None)\n",
    "        if callable(get_attribute):\n",
    "            inner = get_attribute(\"innerText\")\n",
    "            if inner: return inner.strip()\n",
    "            return (getattr(node, \"text\", \"\") or \"\").strip() or None\n",
    "        # Fallback a BeautifulSoup\n",
    "        return node.get_text(\" \", strip=True) or None\n",
    "\n",
    "    @staticmethod\n",
    "    def _abs_link(href: str) -> str:\n",
    "        \"\"\"Convierte links relativos a absolutos de Alibaba.\"\"\"\n",
    "        if not href: return \"\"\n",
    "        if href.startswith(\"//\"): return \"https:\" + href\n",
    "        if href.startswith(\"/\"): return \"https://www.alibaba.com\" + href\n",
    "        return href\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_blocked(driver) -> bool:\n",
    "        \"\"\"Verifica si la p√°gina muestra signos de bloqueo (Captcha/Antibot).\"\"\"\n",
    "        url = (getattr(driver, \"current_url\", \"\") or \"\").lower()\n",
    "        if any(p in url for p in BLOCK_PATTERNS):\n",
    "            return True\n",
    "        html = getattr(driver, \"page_source\", \"\") or \"\"\n",
    "        # Buscar patrones en el texto de la p√°gina\n",
    "        try:\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            soup_text = soup.get_text(separator=\" \", strip=True).lower()\n",
    "        except Exception:\n",
    "            soup_text = html.lower()\n",
    "        return any(p in soup_text for p in BLOCK_PATTERNS)\n",
    "\n",
    "    # ----------------- extracci√≥n de card (Selenium) -----------------\n",
    "\n",
    "    def _extract_card(self, card) -> Optional[Dict]:\n",
    "        \"\"\"Extrae todos los campos de datos de un √∫nico elemento 'card' (Selenium).\"\"\"\n",
    "        if not self.driver: return None\n",
    "        try:\n",
    "            # Link\n",
    "            a = self._first_match(card, self.A_CARD) or card\n",
    "            link = self._abs_link((a.get_attribute(\"href\") or \"\").strip())\n",
    "\n",
    "            # T√≠tulo\n",
    "            titulo_el = self._first_match(card, self.TITLE)\n",
    "            titulo = self._resolve_text(titulo_el) or (a.get_attribute(\"title\") or a.text or \"\").strip() or \"Sin t√≠tulo\"\n",
    "\n",
    "            # Precio + moneda\n",
    "            price_el = self._first_match(card, self.PRICE)\n",
    "            price_text = self._resolve_text(price_el)\n",
    "            precio = limpiar_precio(price_text)\n",
    "            moneda = detectar_moneda(price_text or \"\") if price_text else None\n",
    "\n",
    "            # Original/descuento\n",
    "            pori_el = self._first_match(card, self.PRICE_ORIGINAL)\n",
    "            precio_original = limpiar_precio(self._resolve_text(pori_el) if pori_el else None)\n",
    "            desc_el = self._first_match(card, self.DISCOUNT)\n",
    "            descuento = self._resolve_text(desc_el) if desc_el else None\n",
    "\n",
    "            # MOQ / ventas proxy\n",
    "            moq_el = self._first_match(card, [\"div.searchx-moq\", \"div.price-area-center\"])\n",
    "            moq_val, moq_text = (None, None)\n",
    "            if moq_el:\n",
    "                moq_text = self._resolve_text(moq_el)\n",
    "                moq_val, _ = parse_moq(moq_text or \"\")\n",
    "            ventas = int(moq_val or 0) # Mantener \"ventas\" como proxy para el MOQ\n",
    "\n",
    "            # Proveedor\n",
    "            proveedor_el = self._first_match(card, self.SUPPLIER_NAME)\n",
    "            proveedor = self._resolve_text(proveedor_el) if proveedor_el else None\n",
    "\n",
    "            year_ctry_el = self._first_match(card, self.SUPPLIER_YEAR_COUNTRY)\n",
    "            proveedor_anios, proveedor_pais = (None, None)\n",
    "            if year_ctry_el:\n",
    "                # La l√≥gica de parse_years_country usa elementos Selenium directamente,\n",
    "                # pero para no complicar, aqu√≠ asumimos la extracci√≥n en texto simple\n",
    "                text = (self._resolve_text(year_ctry_el) or \"\").strip()\n",
    "                m_years = _years_re.search(text)\n",
    "                if m_years:\n",
    "                    try: proveedor_anios = int(m_years.group(1))\n",
    "                    except: pass\n",
    "                \n",
    "                # Intentar sacar el pa√≠s del √∫ltimo span si existe\n",
    "                spans = year_ctry_el.find_elements(By.TAG_NAME, \"span\")\n",
    "                if spans:\n",
    "                    maybe_country = (spans[-1].text or \"\").strip()\n",
    "                    if maybe_country and len(maybe_country) <= 3:\n",
    "                        proveedor_pais = maybe_country\n",
    "\n",
    "\n",
    "            verified = bool(self._first_match(card, self.VERIFIED_BADGE))\n",
    "\n",
    "            # Rating\n",
    "            rating_el = self._first_match(card, self.RATING)\n",
    "            rating_score, rating_count = (None, None)\n",
    "            if rating_el:\n",
    "                rating_score, rating_count = parse_rating(self._resolve_text(rating_el) or \"\")\n",
    "\n",
    "            # Selling points\n",
    "            envio_promesa = None\n",
    "            tasa_repeticion = None\n",
    "            sp = self._first_match(card, self.SELLING_POINTS)\n",
    "            if sp:\n",
    "                txt = (self._resolve_text(sp) or \"\").strip()\n",
    "                if \"env√≠o\" in txt.lower():\n",
    "                    envio_promesa = txt\n",
    "                pr = parse_repeat_rate(txt)\n",
    "                if pr is not None:\n",
    "                    tasa_repeticion = pr\n",
    "\n",
    "            return {\n",
    "                \"titulo\": titulo,\n",
    "                \"precio\": precio,\n",
    "                \"precio_original\": precio_original,\n",
    "                \"descuento\": descuento,\n",
    "                \"ventas\": ventas,\n",
    "                \"link\": link,\n",
    "                \"moneda\": moneda,\n",
    "                \"proveedor\": proveedor,\n",
    "                \"proveedor_anios\": proveedor_anios,\n",
    "                \"proveedor_pais\": proveedor_pais,\n",
    "                \"proveedor_verificado\": verified,\n",
    "                \"rating_score\": rating_score,\n",
    "                \"rating_count\": rating_count,\n",
    "                \"moq\": moq_val,\n",
    "                \"moq_texto\": moq_text,\n",
    "                \"envio_promesa\": envio_promesa,\n",
    "                \"tasa_repeticion\": tasa_repeticion,\n",
    "            }\n",
    "        except (NoSuchElementException, StaleElementReferenceException):\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error extrayendo card Alibaba: {e}\")\n",
    "            return None\n",
    "\n",
    "    # ----------------- flujo principal -----------------\n",
    "\n",
    "    def parse(self, producto: str, paginas: int = 4):\n",
    "        \"\"\"Busca el producto en Alibaba y extrae datos de m√∫ltiples p√°ginas.\"\"\"\n",
    "        if not self.driver:\n",
    "            logging.error(\"El driver de Selenium no est√° inicializado. No se puede ejecutar el parseo.\")\n",
    "            return []\n",
    "\n",
    "        resultados: List[Dict] = []\n",
    "        fecha_scraping = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        for page in range(1, paginas + 1):\n",
    "            q = quote_plus(producto)\n",
    "            url = f\"https://www.alibaba.com/trade/search?SearchText={q}&page={page}\"\n",
    "            logging.info(f\"Cargando Alibaba: P√°gina {page} -> {url}\")\n",
    "\n",
    "            cargada = False\n",
    "            for intento in range(3):\n",
    "                try:\n",
    "                    self.driver.get(url)\n",
    "                    self._accept_banners(5)\n",
    "                    WebDriverWait(self.driver, 15).until(\n",
    "                        EC.presence_of_all_elements_located((By.CSS_SELECTOR, \", \".join(self.CARD_CONTAINERS)))\n",
    "                    )\n",
    "                    self._human_scroll_until_growth(max_scrolls=16, pause=1.0)\n",
    "                    cargada = True\n",
    "                    break\n",
    "                except (TimeoutException, WebDriverException) as e:\n",
    "                    logging.warning(f\"Reintento Alibaba p{page} ({intento + 1}): {e}\")\n",
    "                    time.sleep(2.0)\n",
    "\n",
    "            if not cargada:\n",
    "                logging.error(f\"Omitiendo p√°gina {page} por fallos de carga.\")\n",
    "                continue\n",
    "\n",
    "            if self._is_blocked(self.driver):\n",
    "                logging.warning(f\"Posible bloqueo/antibot detectado en Alibaba (p√°gina {page}). Deteniendo scraping.\")\n",
    "                break\n",
    "\n",
    "            # Extracci√≥n con Selenium\n",
    "            bloques = self._find_all_any(self.CARD_CONTAINERS, timeout=8)\n",
    "            logging.info(f\"P√°gina {page}: {len(bloques)} productos (candidatos via Selenium)\")\n",
    "\n",
    "            count_page = 0\n",
    "            for card in bloques:\n",
    "                data = self._extract_card(card)\n",
    "                if data:\n",
    "                    data.update({\n",
    "                        \"pagina\": page,\n",
    "                        \"plataforma\": \"Alibaba\",\n",
    "                        \"fecha_scraping\": fecha_scraping,\n",
    "                    })\n",
    "                    resultados.append(data)\n",
    "                    count_page += 1\n",
    "\n",
    "            logging.info(f\"P√°gina {page}: {count_page} productos v√°lidos.\")\n",
    "            \n",
    "            # Si hay 0 resultados v√°lidos en Selenium, podemos intentar el fallback de BeautifulSoup aqu√≠\n",
    "            # (Tu c√≥digo original incluye el fallback, pero por simplicidad y dado que Selenium ya carg√≥ la p√°gina,\n",
    "            # lo omitimos aqu√≠, ya que el objetivo es asegurar la extracci√≥n con el driver)\n",
    "            \n",
    "            if count_page == 0:\n",
    "                 logging.warning(f\"No se encontraron productos v√°lidos en la p√°gina {page}. Se asume fin o bloqueo.\")\n",
    "                 break\n",
    "                 \n",
    "        return resultados\n",
    "\n",
    "\n",
    "# --- 4. EJECUCI√ìN EN NOTEBOOK ---\n",
    "\n",
    "def run_scraper_test(producto: str, paginas: int = 2):\n",
    "    \"\"\"Funci√≥n de prueba para el notebook.\"\"\"\n",
    "    print(f\"Buscando el producto: '{producto}' en {paginas} p√°ginas de Alibaba...\")\n",
    "    \n",
    "    # IMPORTANTE: Aseg√∫rate de que el path a tu chromedriver es correcto si no est√° en el PATH\n",
    "    # driver_path = \"/ruta/a/tu/chromedriver\" # Descomenta y ajusta si es necesario\n",
    "    driver_path = None # Usar None si el driver est√° en el PATH\n",
    "    \n",
    "    # Usamos el manejador de contexto 'with' para asegurar que el driver se cierra\n",
    "    try:\n",
    "        with AlibabaScraper(headless=True, driver_path=driver_path) as scraper:\n",
    "            df_resultados = pd.DataFrame()\n",
    "            resultados = scraper.parse(producto, paginas=paginas)\n",
    "            \n",
    "            if resultados:\n",
    "                df_resultados = pd.DataFrame(resultados)\n",
    "                # Reordenar columnas para mejor visualizaci√≥n\n",
    "                cols = ['titulo', 'precio', 'moneda', 'moq', 'proveedor', 'proveedor_pais', \n",
    "                        'rating_score', 'rating_count', 'link', 'pagina', 'plataforma']\n",
    "                df_resultados = df_resultados[[c for c in cols if c in df_resultados.columns] + \n",
    "                                              [c for c in df_resultados.columns if c not in cols]]\n",
    "                \n",
    "                print(f\"\\n‚úÖ Extracci√≥n exitosa: {len(df_resultados)} productos encontrados.\")\n",
    "                \n",
    "                # Mostrar los primeros resultados\n",
    "                display(df_resultados.head(10))\n",
    "                \n",
    "                # An√°lisis B√°sico\n",
    "                print(\"\\n--- An√°lisis R√°pido ---\")\n",
    "                avg_price = df_resultados['precio'].mean()\n",
    "                print(f\"Precio promedio (limpio): {df_resultados['moneda'].mode().iloc[0] if not df_resultados['moneda'].empty else ''} {avg_price:.2f}\")\n",
    "\n",
    "                top_countries = df_resultados['proveedor_pais'].value_counts().head(5)\n",
    "                print(\"\\nTop 5 Pa√≠ses de Proveedor:\")\n",
    "                print(top_countries)\n",
    "                \n",
    "                return df_resultados\n",
    "            else:\n",
    "                print(\"\\n‚ùå No se encontraron resultados o hubo un error al cargar la primera p√°gina.\")\n",
    "                return pd.DataFrame()\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"\\nüõë Error cr√≠tico durante la ejecuci√≥n del scraper: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- EJECUCI√ìN DE PRUEBA ---\n",
    "# Puedes cambiar el producto y el n√∫mero de p√°ginas a tu gusto\n",
    "df = run_scraper_test(producto=\"electronic component kit\", paginas=2)\n",
    "\n",
    "# Opcional: Guardar los resultados\n",
    "# if not df.empty:\n",
    "#     df.to_excel(\"alibaba_resultados.xlsx\", index=False)\n",
    "#     print(\"\\nResultados guardados en alibaba_resultados.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
